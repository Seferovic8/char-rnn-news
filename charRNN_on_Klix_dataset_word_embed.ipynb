{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06A036uUU2jA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "import sys\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9YRZhHTWiUR",
        "outputId": "330b9708-28b4-42d4-8b6b-08d35a5eda75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tTh0aFnVXzx"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHcVu_BGhnT5"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3sv8fpaVGQq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Seferovic/bosnian-news-articles-dataset-from-klixba\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37av5t32VXQb"
      },
      "outputs": [],
      "source": [
        "df = ds['train'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "X5aSyeb0Xbct",
        "outputId": "cdf88a85-1147-4726-deb1-c2be4d0c8809"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>link</th>\n",
              "      <th>article_class</th>\n",
              "      <th>article_class_name</th>\n",
              "      <th>num_of_comments</th>\n",
              "      <th>num_of_shares</th>\n",
              "      <th>picture_path</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ukrajinski piloti započeli obuku za upravljanj...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/ukrajinski-...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Obučavaju ih Amerikanci</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Ukrajinski piloti započeli su zajedničku obuku...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Košarkaši BiH se danas protiv Poljske bore za ...</td>\n",
              "      <td>https://www.klix.ba/sport/kosarka/kosarkasi-bi...</td>\n",
              "      <td>sport</td>\n",
              "      <td>Finale pretkvalifikacija</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Košarkaška reprezentacija Bosne i Hercegovine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nakon više od 80 godina Kaliforniji se sprema ...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/nakon-vise-...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Uragan Hilary</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Uragan Hilary koji se kreće prema pacifičkoj o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kremlj je na popis stranih agenata u Rusiji uv...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/kremlj-je-n...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Paranoja u Moskvi</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/23...</td>\n",
              "      <td>Rusko ministarstvo pravde uključilo je na tako...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Savo Manojlović odgovorio Ani Brnabić: Da li s...</td>\n",
              "      <td>https://www.klix.ba/vijesti/regija/savo-manojl...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Pitanje odgovornosti</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Direktor pokreta \"Kreni-Promeni\" Savo Manojlov...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Ukrajinski piloti započeli obuku za upravljanj...   \n",
              "1  Košarkaši BiH se danas protiv Poljske bore za ...   \n",
              "2  Nakon više od 80 godina Kaliforniji se sprema ...   \n",
              "3  Kremlj je na popis stranih agenata u Rusiji uv...   \n",
              "4  Savo Manojlović odgovorio Ani Brnabić: Da li s...   \n",
              "\n",
              "                                                link article_class  \\\n",
              "0  https://www.klix.ba/vijesti/svijet/ukrajinski-...       vijesti   \n",
              "1  https://www.klix.ba/sport/kosarka/kosarkasi-bi...         sport   \n",
              "2  https://www.klix.ba/vijesti/svijet/nakon-vise-...       vijesti   \n",
              "3  https://www.klix.ba/vijesti/svijet/kremlj-je-n...       vijesti   \n",
              "4  https://www.klix.ba/vijesti/regija/savo-manojl...       vijesti   \n",
              "\n",
              "         article_class_name  num_of_comments num_of_shares  \\\n",
              "0   Obučavaju ih Amerikanci                0             0   \n",
              "1  Finale pretkvalifikacija                8             0   \n",
              "2             Uragan Hilary               17            18   \n",
              "3         Paranoja u Moskvi                4            27   \n",
              "4      Pitanje odgovornosti                8             8   \n",
              "\n",
              "                                        picture_path  \\\n",
              "0  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "1  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "2  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "3  https://static.klix.ba/media/images/vijesti/23...   \n",
              "4  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "\n",
              "                                                text  \n",
              "0  Ukrajinski piloti započeli su zajedničku obuku...  \n",
              "1  Košarkaška reprezentacija Bosne i Hercegovine ...  \n",
              "2  Uragan Hilary koji se kreće prema pacifičkoj o...  \n",
              "3  Rusko ministarstvo pravde uključilo je na tako...  \n",
              "4  Direktor pokreta \"Kreni-Promeni\" Savo Manojlov...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xPfaLMUXk1p"
      },
      "outputs": [],
      "source": [
        "text = df['text'].values[:1500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3oHEZGyaQrH"
      },
      "outputs": [],
      "source": [
        "text = ''.join(text)\n",
        "text = text[:3_050_000].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIRXyiXXa2NC",
        "outputId": "e4e4241c-7897-4356-9402-a4272689d1f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2714674"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTUGgwlqelto"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mtWZs0FMqnh",
        "outputId": "e0d62be2-e010-4a9e-f2db-7a438cba9d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'š', 'đ', 'ž', 'č', 'ć', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '?', '.', ',', '\"', '(', ')', '+', '-', '/', '@', '%', '–', \"'\", ':', ' ', '\\n']\n"
          ]
        }
      ],
      "source": [
        "accepted_text= string.ascii_lowercase + 'šđžčć' + string.digits + '!?.,\"()+-/@%–' + \"':\" + ' ' + '\\n'\n",
        "chars = [x for x in accepted_text]\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftNIYLSGYztB"
      },
      "outputs": [],
      "source": [
        "text = ''.join([char for char in text if char in accepted_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozofNyJbd-IH"
      },
      "outputs": [],
      "source": [
        "test_size = 0.15\n",
        "train_text = text[:int(len(text)*(1-test_size))]\n",
        "test_text = text[int(len(text)*(1-test_size)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR-UN4k3fac7",
        "outputId": "5ae38702-e874-41fa-c2e9-6eca245c90eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2303949, 406580)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_text), len(test_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-AcUe3Uhr6G"
      },
      "source": [
        "## Create vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1AJxN5ZXbBf"
      },
      "source": [
        "### Character vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEyp7_THVhi6"
      },
      "outputs": [],
      "source": [
        "character_vocab={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE9IdEKwOTGP"
      },
      "outputs": [],
      "source": [
        "for i, char in enumerate(chars):\n",
        "  character_vocab[char] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R89xd0_4PAIw",
        "outputId": "83859995-a234-4cc0-c619-860dbb944310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 58\n"
          ]
        }
      ],
      "source": [
        "character_vocab_size = len(character_vocab)\n",
        "print(f\"Vocabulary size: {character_vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5V1z_qySPEi"
      },
      "source": [
        "### Word vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9FlnszHXfjI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def remove_puncation(word):\n",
        "  return re.sub(r\"[^\\w\\s'-]\", '', word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-zPh3w6Re5F"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "word_vocab ={'<SOS>':0,'<UNK>':1,'<PAD>':2}\n",
        "for word in text.split():\n",
        "  word =remove_puncation(word)\n",
        "  if word not in word_vocab:\n",
        "    word_vocab[word] = i\n",
        "    i+=1\n",
        "word_vocab['<EOS>'] = len(word_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQH0QYWgbSZO",
        "outputId": "b14f9ba5-99e4-4ed4-afa6-82e4175040a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "naraštaje\n"
          ]
        }
      ],
      "source": [
        "k=0\n",
        "for i in word_vocab:\n",
        "  if word_vocab[i] == 20879:\n",
        "    print(i)\n",
        "    break\n",
        "  k+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa-Bsy3iVP64",
        "outputId": "85efc84b-c361-4989-b6d1-37d837fc42c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 56209\n"
          ]
        }
      ],
      "source": [
        "word_vocab_size = len(word_vocab)\n",
        "print(f\"Vocabulary size: {word_vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTElt8NhcXm"
      },
      "source": [
        "## Create Custom tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OMntxT_gvR5"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "  def __init__(self,char_vocabulary, word_vocabulary):\n",
        "    self.char_vocabulary = char_vocabulary\n",
        "    self.word_vocabulary = word_vocabulary\n",
        "  def __call__(self,sequence, label=False):\n",
        "    sequence = sequence.lower()\n",
        "    if label:\n",
        "      token = F.one_hot(torch.tensor(self.char_vocabulary[sequence]),num_classes=len(self.char_vocabulary))\n",
        "      return token.type(torch.float32)\n",
        "    char_tokens =[]\n",
        "    word_tokens =[0]\n",
        "    for letter in sequence:\n",
        "      char_tokens.append(self.char_vocabulary[letter])\n",
        "\n",
        "    for word in sequence.split()[1:-1]:\n",
        "      if remove_puncation(word) in self.word_vocabulary:\n",
        "        word_tokens.append(self.word_vocabulary[remove_puncation(word)])\n",
        "      else:\n",
        "        word_tokens.append(1)\n",
        "\n",
        "    word_tokens.append(self.word_vocabulary['<EOS>'])\n",
        "    char_tokens = torch.tensor(char_tokens)\n",
        "    word_tokens = torch.tensor(word_tokens)\n",
        "\n",
        "    return char_tokens,word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95KSR07NXt7t"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(character_vocab,word_vocabulary=word_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AmykNE2gLoR"
      },
      "source": [
        "## Create Custom dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBSUpM46Z8CH"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self,text,T,tokenizer=None):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.text = text\n",
        "    self.T = T\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)-self.T\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    x = self.text[idx:idx+self.T]\n",
        "    y = self.text[idx+self.T]\n",
        "\n",
        "    if self.tokenizer:\n",
        "      char_x,word_x = self.tokenizer(x)\n",
        "      y = self.tokenizer(y, label=True)\n",
        "\n",
        "\n",
        "    #x = x.astype(np.float32)\n",
        "   # y = np.array(y).reshape(-1,1).astype(np.float32)\n",
        "    return (char_x.long(),word_x.long()), y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yppR6NQygH5T"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AFpYZcmcpl7"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_text,500,tokenizer=tokenizer)\n",
        "test_dataset = TextDataset(test_text,500,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLC0REiedURt",
        "outputId": "5c19cb9f-a7bd-43bf-c3c3-13a4cfbb352f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2303449, 406080)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9BPv29Yc6iV",
        "outputId": "321079ed-cafa-4425-a339-32f50d175842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([20, 10, 17,  0,  9,  8, 13, 18, 10,  8, 56, 15,  8, 11, 14, 19,  8, 56,\n",
            "        25,  0, 15, 14, 29,  4, 11,  8, 56, 18, 20, 56, 25,  0,  9,  4,  3, 13,\n",
            "         8, 29, 10, 20, 56, 14,  1, 20, 10, 20, 56, 25,  0, 56, 20, 15, 17,  0,\n",
            "        21, 11,  9,  0, 13,  9,  4, 56,  1, 14, 17,  1,  4, 13,  8, 12, 56,  0,\n",
            "        21,  8, 14, 13,  8, 12,  0, 56,  5, 49, 32, 37, 56, 18,  0, 56,  0, 12,\n",
            "         4, 17,  8, 29, 10,  8, 12, 56,  8, 13, 18, 19, 17, 20, 10, 19, 14, 17,\n",
            "         8, 12,  0, 56, 20, 56, 20, 10, 17,  0,  9,  8, 13,  8, 43, 56, 14, 21,\n",
            "        20, 56,  8, 13,  5, 14, 17, 12,  0,  2,  8,  9, 20, 56,  9,  4, 56, 25,\n",
            "         0, 56, 12,  4,  3,  8,  9,  4, 56, 15, 14, 19, 21, 17,  3,  8, 14, 56,\n",
            "        20, 10, 17,  0,  9,  8, 13, 18, 10,  8, 56, 10, 14, 12,  0, 13,  3,  0,\n",
            "        13, 19, 56, 14, 11,  4, 10, 18,  0, 13,  3, 17, 56, 14, 11,  4, 18,  7,\n",
            "         2,  7, 20, 10, 43, 56, 10,  0, 25,  0, 14, 56,  9,  4, 56,  3,  0, 56,\n",
            "         1,  8, 56, 15,  8, 11, 14, 19,  8, 56, 12, 14,  6, 11,  8, 56, 18,  0,\n",
            "        21, 11,  0,  3,  0, 19,  8, 56, 20, 15, 14, 19, 17,  4,  1, 20, 56, 14,\n",
            "        21, 14,  6, 56,  1, 14, 17,  1,  4, 13, 14,  6, 56,  0, 21,  8, 14, 13,\n",
            "         0, 56, 25,  0, 56, 29,  4, 19,  8, 17,  8, 56, 12,  9,  4, 18,  4,  2,\n",
            "         0, 44, 56,  8,  0, 10, 14, 56,  9,  4, 56, 20, 10, 20, 15,  0, 13, 56,\n",
            "        15,  4, 17,  8, 14,  3, 56, 14,  1, 20, 10,  4, 56, 19, 17,  4,  1,  0,\n",
            "        14, 56,  8, 25, 13, 14, 18,  8, 19,  8, 56, 34, 33, 56, 12,  9,  4, 18,\n",
            "         4,  2,  0, 43, 56, 20, 10, 17,  0,  9,  8, 13, 18, 10,  8, 56, 12,  8,\n",
            "        13,  8, 18, 19,  0, 17, 56, 14,  3,  1, 17,  0, 13,  4, 56, 14, 11,  4,\n",
            "        10, 18,  8,  9, 56, 17,  4, 25, 13,  8, 10, 14, 21, 56, 19,  0, 10, 14,\n",
            "        27,  4, 17, 56,  9,  4, 56, 17,  4, 10,  0, 14, 56,  3,  0, 56,  9,  4,\n",
            "        56, 14,  1, 20, 10,  0, 56, 13,  0, 56,  1, 14, 17,  1,  4, 13,  8, 12,\n",
            "        56,  0, 21,  8, 14, 13,  8, 12,  0, 56,  5, 49, 32, 37, 56, 15, 14, 29,\n",
            "         4, 11,  0, 56, 19,  4, 56,  9,  4, 56,  3, 14,  3,  0, 14, 56,  3,  0,\n",
            "        56, 18, 20, 56, 18,  4, 56, 18,  0, 56, 15,  8, 11, 14, 19,  8, 12,  0,\n",
            "        56, 15, 14, 29,  4, 11,  8, 56, 14,  1, 20, 29,  0, 21]), tensor([    0,     3,     4,     5,     6,     7,     8,     9,    10,    11,\n",
            "           12,    13,    14,    15,    16,    17,    18,    19,    20,     8,\n",
            "           21,    22,     2,    23,    24,    25,    26,    20,    27,    28,\n",
            "            3,    29,    30,    31,    32,    33,    34,     8,    35,    36,\n",
            "           37,    20,    38,    39,    40,    41,    42,    43,    36,     2,\n",
            "           44,    45,    46,    47,    48,    20,    49,    27,    20,    50,\n",
            "           51,    10,    11,    12,    52,    53,    20,    54,    27,     5,\n",
            "           55,    13,    56,    57, 56208])) tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "for i,k in train_dataset:\n",
        "  print(i,k)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8WD7ZI0iBgk"
      },
      "source": [
        "## Initilize DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltI0uNLAeJJq"
      },
      "outputs": [],
      "source": [
        "def collate_pad_sequences(batch):\n",
        "    # Assuming each item in batch is a tuple (data, label)\n",
        "    # Sort the batch in descending order of length\n",
        "    #sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "\n",
        "    # Separate data and labels\n",
        "    char_data = []\n",
        "    word_data = []\n",
        "    labels = []\n",
        "\n",
        "    max_len= np.max([x[0][1].size(0) for x in batch])\n",
        "    for x in batch:\n",
        "      labels.append(x[1].numpy())\n",
        "      padded = torch.tensor([2 for i in range(max_len-x[0][1].size(0))])\n",
        "      mfcc = torch.cat((padded, x[0][1]),0)\n",
        "      word_data.append(mfcc)\n",
        "      char_data.append(x[0][0])\n",
        "\n",
        "\n",
        "    labels = torch.tensor(labels)\n",
        "    char_data = torch.tensor(np.array(char_data))\n",
        "    word_data = torch.tensor(np.array(word_data))\n",
        "\n",
        "    return (char_data.long(),word_data.long()), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCpde61bc_7W"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,collate_fn=collate_pad_sequences)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64,collate_fn=collate_pad_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X5jy-PGMv5g",
        "outputId": "af3be51a-ecd5-48a0-e99e-05cb13a067b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:  (tensor([[ 9,  8, 44,  ...,  8,  7, 56],\n",
            "        [10, 14, 12,  ...,  8, 30, 56],\n",
            "        [44, 56, 18,  ..., 56, 33, 33],\n",
            "        ...,\n",
            "        [56,  9,  4,  ...,  4,  2, 14],\n",
            "        [21,  8,  9,  ..., 12, 56,  6],\n",
            "        [11,  0, 13,  ..., 20,  1, 11]]), tensor([[    2,     2,     2,  ..., 18104, 30167, 56208],\n",
            "        [    2,     2,     2,  ...,  1700,  1134, 56208],\n",
            "        [    2,     2,     2,  ..., 50107, 10206, 56208],\n",
            "        ...,\n",
            "        [    2,     2,     2,  ...,   889,  2255, 56208],\n",
            "        [    2,     2,     2,  ...,    16,  4420, 56208],\n",
            "        [    2,     2,     2,  ...,  1113,  2573, 56208]])) char shape:  torch.Size([64, 500]) word shape:  torch.Size([64, 88])\n",
            "targets:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) shape:  torch.Size([64, 58])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_623/3492700492.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  labels = torch.tensor(labels)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_loader:\n",
        "  print('inputs: ', inputs, 'char shape: ', inputs[0].shape, 'word shape: ', inputs[1].shape)\n",
        "  print('targets: ', targets, 'shape: ', targets.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osP74uLsiDCI"
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxUNhBPKi4Nl",
        "outputId": "a42a5054-47cf-4312-f039-9e71b84985f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1A-aXh1nH7n"
      },
      "outputs": [],
      "source": [
        "class CharRNN(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,n_hidden,n_layers,n_outputs):\n",
        "    super(CharRNN,self).__init__()\n",
        "    self.V = vocab_size\n",
        "    self.D = embed_size\n",
        "    self.M = n_hidden\n",
        "    self.L = n_layers\n",
        "    self.K = n_outputs\n",
        "\n",
        "    self.embedding = nn.Embedding(self.V,self.D)\n",
        "\n",
        "    # Initalize rnn and fc layers\n",
        "    self.rnn = nn.LSTM(input_size=self.D,\n",
        "                      hidden_size=self.M,\n",
        "                      num_layers=self.L,\n",
        "                      batch_first=True)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.M, self.K),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "  def forward(self, X):\n",
        "    h0 = torch.zeros(self.L,X.size(0),self.M).to(device)\n",
        "    c0 = torch.zeros(self.L,X.size(0),self.M).to(device)\n",
        "\n",
        "    # Embedding layer:\n",
        "\n",
        "    out = self.embedding(X)\n",
        "    # pass through rnn\n",
        "\n",
        "    out,_ = self.rnn(out,(h0,c0))\n",
        "    out = F.relu(out)\n",
        "    out = self.fc(out[:,-1,:])\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHGNgVC3nu9y"
      },
      "outputs": [],
      "source": [
        "class WordRNN(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,n_hidden,n_layers,n_outputs):\n",
        "    super(WordRNN,self).__init__()\n",
        "    self.V = vocab_size\n",
        "    self.D = embed_size\n",
        "    self.M = n_hidden\n",
        "    self.L = n_layers\n",
        "    self.K = n_outputs\n",
        "\n",
        "    self.embedding = nn.Embedding(self.V,self.D)\n",
        "\n",
        "    # Initalize rnn and fc layers\n",
        "    self.rnn = nn.GRU(input_size=self.D,\n",
        "                      hidden_size=self.M,\n",
        "                      num_layers=self.L,\n",
        "                      batch_first=True)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.M, self.K),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "\n",
        "    # Embedding layer:\n",
        "\n",
        "    out = self.embedding(X)\n",
        "    # pass through rnn\n",
        "\n",
        "    out,_ = self.rnn(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc(out[:,-1,:])\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naMGrVxjiE7a"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,vocab_sizes,embed_sizes,n_hidden,n_layers,hidden_outputs,n_outputs):\n",
        "    super(RNN,self).__init__()\n",
        "    self.CV, self.WV = vocab_sizes\n",
        "    self.CD, self.WD = embed_sizes\n",
        "    self.M = n_hidden\n",
        "    self.CL, self.WL = n_layers\n",
        "    self.HO = hidden_outputs\n",
        "    self.K = n_outputs\n",
        "\n",
        "    self.char_rnn=CharRNN(\n",
        "            vocab_size=self.CV,\n",
        "            embed_size=self.CD,\n",
        "            n_hidden=self.M,\n",
        "            n_layers=self.CL,\n",
        "            n_outputs=self.HO)\n",
        "\n",
        "    self.word_rnn=CharRNN(\n",
        "            vocab_size=self.WV,\n",
        "            embed_size=self.WD,\n",
        "            n_hidden=self.M,\n",
        "            n_layers=self.WL,\n",
        "            n_outputs=self.HO)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.HO*2, 1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512,self.K)\n",
        "        )\n",
        "\n",
        "  def forward(self, X):\n",
        "    char_outputs=self.char_rnn(X[0])\n",
        "    word_outputs = self.word_rnn(X[1])\n",
        "    out = torch.cat((char_outputs,word_outputs),1)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTbeyEnfjD7v",
        "outputId": "e2f1be19-07a2-4e4e-9129-0c77962bd012"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (char_rnn): CharRNN(\n",
              "    (embedding): Embedding(58, 40)\n",
              "    (rnn): LSTM(40, 192, num_layers=5, batch_first=True)\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=192, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (word_rnn): CharRNN(\n",
              "    (embedding): Embedding(56209, 16)\n",
              "    (rnn): LSTM(16, 192, num_layers=3, batch_first=True)\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=192, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=58, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RNN(vocab_sizes=(character_vocab_size,word_vocab_size),\n",
        "            embed_sizes=(40,16),\n",
        "            n_hidden=192,\n",
        "            hidden_outputs=256,\n",
        "            n_layers=(5,3),\n",
        "            n_outputs=character_vocab_size)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlGZoZ8FjVkw",
        "outputId": "c8c70708-db86-48fd-c10c-96a77f6227fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 500]) torch.Size([64, 91])\n",
            "torch.Size([64, 58])\n"
          ]
        }
      ],
      "source": [
        "for i, k in train_loader:\n",
        "  i = (i[0].to(device), i[1].to(device))\n",
        "  print(i[0].shape,i[1].shape)\n",
        "  tada = model(i)\n",
        "  print(tada.size())\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Web7uUkljiAX"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XPgERT9mkFX"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DltiUnFLpj1R"
      },
      "outputs": [],
      "source": [
        "from helper_functions import progress_bar, plot_loss_curves,SaveModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbAbUut_mysE"
      },
      "outputs": [],
      "source": [
        "save_model_checkpoint = SaveModelCheckpoint(path=\"model1_checkpoint.pt\")\n",
        "best_val_loss=float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVT2RHKam6D7",
        "outputId": "fb1d11e5-e930-4641-c767-02597b37cf7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 1, val_loss improved from: inf to: 1.6846\u001b[0m\n",
            "Epoch 1/30, Train loss: 1.9356, Val loss: 1.6846, Duration: 4:21:22.541161\n",
            "-------------------------------------------------------------\n",
            "Epoch [2/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 2, val_loss improved from: 1.6846 to: 1.5644\u001b[0m\n",
            "Epoch 2/30, Train loss: 1.5751, Val loss: 1.5644, Duration: 4:22:40.297453\n",
            "-------------------------------------------------------------\n",
            "Epoch [3/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 3, val_loss improved from: 1.5644 to: 1.5271\u001b[0m\n",
            "Epoch 3/30, Train loss: 1.4890, Val loss: 1.5271, Duration: 4:22:41.899877\n",
            "-------------------------------------------------------------\n",
            "Epoch [4/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 4, val_loss improved from: 1.5271 to: 1.5009\u001b[0m\n",
            "Epoch 4/30, Train loss: 1.4473, Val loss: 1.5009, Duration: 4:22:46.701701\n",
            "-------------------------------------------------------------\n",
            "Epoch [5/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 5, val_loss improved from: 1.5009 to: 1.4926\u001b[0m\n",
            "Epoch 5/30, Train loss: 1.4230, Val loss: 1.4926, Duration: 4:22:49.795432\n",
            "-------------------------------------------------------------\n",
            "Epoch [6/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 6, val_loss improved from: 1.4926 to: 1.4778\u001b[0m\n",
            "Epoch 6/30, Train loss: 1.4076, Val loss: 1.4778, Duration: 4:19:20.702357\n",
            "-------------------------------------------------------------\n",
            "Epoch [7/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "Epoch 7/30, Train loss: 1.4007, Val loss: 1.4778, Duration: 4:19:08.272302\n",
            "-------------------------------------------------------------\n",
            "Epoch [8/30]\n",
            "Validation: Batch 6345/6345 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 8, val_loss improved from: 1.4778 to: 1.4721\u001b[0m\n",
            "Epoch 8/30, Train loss: 1.3878, Val loss: 1.4721, Duration: 4:19:20.927073\n",
            "-------------------------------------------------------------\n",
            "Epoch [9/30]\n",
            "Batch 22030/35992 - [==============================....................]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[38], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     30\u001b[0m current_batch \u001b[38;5;241m=\u001b[39m progress_bar(current_batch,total_batches)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:581\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_div_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n\u001b[1;32m    583\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epoches=30\n",
        "train_losses = np.zeros(epoches)\n",
        "val_losses = np.zeros(epoches)\n",
        "\n",
        "for it in range(epoches):\n",
        "  t0 = datetime.now()\n",
        "  model.train() # set model to train mode\n",
        "  print(f\"Epoch [{it+1}/{epoches}]\")\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  current_batch = 0\n",
        "  total_batches = len(train_loader)\n",
        "  # train\n",
        "  for inputs,targets in train_loader:\n",
        "    # move data to gpu\n",
        "    inputs,targets = (inputs[0].to(device), inputs[1].to(device)),targets.to(device)\n",
        "    #inputs = inputs.permute(0,2,1)\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,targets)\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.item())\n",
        "    current_batch = progress_bar(current_batch,total_batches)\n",
        "\n",
        "  model.eval() # set model to eval mode\n",
        "  current_batch = 0\n",
        "  total_batches = len(test_loader)\n",
        "  for inputs,targets in test_loader:\n",
        "    # move data to gpu\n",
        "    inputs,targets = (inputs[0].to(device), inputs[1].to(device)),targets.to(device)\n",
        "   # inputs = inputs.permute(0,2,1)\n",
        "\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,targets)\n",
        "\n",
        "    val_loss.append(loss.item())\n",
        "\n",
        "    current_batch = progress_bar(current_batch,total_batches,validation=True)\n",
        "\n",
        "  # calculate loss\n",
        "  train_loss = np.mean(train_loss)\n",
        "  print('\\r')\n",
        "  val_loss = np.mean(val_loss)\n",
        "  best_val_loss=  save_model_checkpoint(val_loss,best_val_loss,train_loss,it, model=model, optimizer=optimizer)\n",
        "  # append loss\n",
        "  train_losses[it]=train_loss\n",
        "  val_losses[it]=val_loss\n",
        "  dt = datetime.now() - t0\n",
        "  print(f\"Epoch {it+1}/{epoches}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Duration: {dt}\")\n",
        "  print('-------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaBW9j7em_lx"
      },
      "outputs": [],
      "source": [
        "print_second = False\n",
        "if print_second:\n",
        "  plot_loss_curves(train_losses2,val_losses2,train_losses,val_losses,)\n",
        "else:\n",
        "  plot_loss_curves(train_losses,val_losses)\n",
        "  train_losses2,val_losses2 = train_losses,val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZdfDtlYwufB"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "# train accuracy\n",
        "n_correct=0\n",
        "n_total=0\n",
        "for inputs,targets in train_loader:\n",
        "  # move data to gpu\n",
        "  inputs,targets = inputs.to(device),targets.to(device)\n",
        "  #inputs = inputs.permute(0,2,1)\n",
        "\n",
        "  # make prediction\n",
        "  outputs = model(inputs)\n",
        "  _,predictions = torch.max(outputs,1)\n",
        "  targets = torch.argmax(targets, dim=1)\n",
        "  # update counts\n",
        "  n_correct+=(predictions==targets).sum().item()\n",
        "  n_total+=targets.shape[0]\n",
        "train_acc = n_correct/n_total\n",
        "\n",
        "# test accuracy\n",
        "n_correct=0\n",
        "n_total=0\n",
        "for inputs,targets in test_loader:\n",
        "  # move data to gpu\n",
        "  inputs,targets = inputs.to(device),targets.to(device)\n",
        "  #inputs = inputs.permute(0,2,1)\n",
        "\n",
        "  # make prediction\n",
        "  outputs = model(inputs)\n",
        "  _,predictions = torch.max(outputs,1)\n",
        "  targets = torch.argmax(targets, dim=1)\n",
        "  # update counts\n",
        "  n_correct+=(predictions==targets).sum().item()\n",
        "  n_total+=targets.shape[0]\n",
        "test_acc = n_correct/n_total\n",
        "\n",
        "print(f\"Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDq95uETDYti"
      },
      "outputs": [],
      "source": [
        "vocabulary = {y: x for x, y in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUAAH3gqEOju"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y5ZT9mN9945"
      },
      "outputs": [],
      "source": [
        "tekst = text[500000:500100]\n",
        "tekst='FK Željezničar je uoči sjednice obavijestio medije da'\n",
        "#tekst = '''Apsolutni junak Zmajeva večeras je bio golman Nikola Vasilj, koji je sa pet izvanrednih intervencija sačuvao svoju mrežu netaknutom, pa je najzaslužniji za osvojeni bod našeg nacionalnog tima.#\n",
        "#Od početka utakmice inicijativu je imala selekcija Mađarske, ali ipak se dugo čekalo na prava uzbuđenja jer smo gledali uspavanku na terenu.'''\n",
        "for i in range(50):\n",
        "  data = tokenizer(tekst[-100:])\n",
        "  data = data.reshape(1,-1)\n",
        "  data = data.to(device)\n",
        "  outputs = model(data)\n",
        "  out = torch.argmax(outputs,1)\n",
        "  new_letter = vocabulary[out.cpu().numpy()[0]]\n",
        "  tekst = tekst+new_letter\n",
        "  print(tekst)\n",
        "  time.sleep(0.5)\n",
        "  print('---------------------------------------------------')\n",
        "#print(tekst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47wRFrhPAhy_"
      },
      "outputs": [],
      "source": [
        "def next_char(text, temperature=1):\n",
        "    # Predict using the model (assuming text is already processed into the right tensor format)\n",
        "    with torch.no_grad():\n",
        "      data = tokenizer(text)\n",
        "      data = data.reshape(1,-1)\n",
        "      data = data.to(device)\n",
        "      logits = model(data)  # Replace with proper text input processing\n",
        "\n",
        "    # Get the logits for the last predicted character\n",
        "    #logits = y_proba[:, -1, :]  # Assuming y_proba has shape [batch_size, seq_len, vocab_size]\n",
        "\n",
        "    # Rescale logits using temperature\n",
        "    rescaled_logits = logits / temperature\n",
        "\n",
        "    # Apply softmax to get probabilities and then sample from the categorical distribution\n",
        "    probabilities = F.softmax(rescaled_logits, dim=-1)\n",
        "    char_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "\n",
        "    # Get the vocabulary and return the corresponding character\n",
        "    return vocabulary[char_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN0xodgUVbVr"
      },
      "outputs": [],
      "source": [
        "def extend_text(text, n_chars=100, temperature=1):\n",
        "    class bcolors:\n",
        "        HEADER = '\\033[95m'\n",
        "        OKBLUE = '\\033[94m'\n",
        "        OKCYAN = '\\033[96m'\n",
        "        OKGREEN = '\\033[92m'\n",
        "        WARNING = '\\033[93m'\n",
        "        FAIL = '\\033[91m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        UNDERLINE = '\\033[4m'\n",
        "\n",
        "    first_len=len(text)\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    print(f\"{bcolors.OKGREEN}{text[:first_len]}{bcolors.ENDC}{text[first_len:]}\")\n",
        "    #return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G5tLomVVcLs",
        "outputId": "6e1053d8-f83a-4b09-9982-c0a218f4f53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z vjenčanog prstena te je na taj način potvrdila da je vijest o razvodu tačna. ona je u aprilu bila u zajednici. tarocinov materijalna fodica (društvo i gonky ne svaki 10 mjesta ispred svog nevjetove \n"
          ]
        }
      ],
      "source": [
        "tekst = text[500000:500100]\n",
        "\n",
        "print(extend_text(tekst, temperature=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORwbqV7cVg0F",
        "outputId": "05b0de28-0718-4ee4-8b84-fc0176781fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ali, želja Ukrajine za članstvom u EU posebno je stvorila opipljiv strah na zapadnom Balkanu da će biti ostavljena po strani. Srbija ne želi da ima ništa sa NATO-om, a njen blizak odnos sa Moskvom zakomplikovao je nastojanja Beograda za ulazak u EU, još više od ruske invazije velikih razmjera na Ukrajinu.\n",
            "\n",
            "Da nije bilo invazije na Ukrajinu, pristupni pregovori sa Albanijom i Sjevernom Makedonijom zasigurno bi zaglavili, a Bosna i Hercegovina ne bi bila priznata kao kandidat za EU. Možda se i EU ne bi složila oko budžeta za svoj novi plan rasta od šest milijardi eura za Zapadni Balkan. Plan uslovljava evropska ulaganja reformama na Balkanu, ali ako se ostvari njegov puni potencijal, zemlje u regionu mogle bi dobiti po glavi stanovnika skoro onoliko novi dan provjere je i dobio je potpis u karakteru, a nakon što je na veliki prijenos i naših organizac\n"
          ]
        }
      ],
      "source": [
        "tekat=\"\"\"Ali, želja Ukrajine za članstvom u EU posebno je stvorila opipljiv strah na zapadnom Balkanu da će biti ostavljena po strani. Srbija ne želi da ima ništa sa NATO-om, a njen blizak odnos sa Moskvom zakomplikovao je nastojanja Beograda za ulazak u EU, još više od ruske invazije velikih razmjera na Ukrajinu.\n",
        "\n",
        "Da nije bilo invazije na Ukrajinu, pristupni pregovori sa Albanijom i Sjevernom Makedonijom zasigurno bi zaglavili, a Bosna i Hercegovina ne bi bila priznata kao kandidat za EU. Možda se i EU ne bi složila oko budžeta za svoj novi plan rasta od šest milijardi eura za Zapadni Balkan. Plan uslovljava evropska ulaganja reformama na Balkanu, ali ako se ostvari njegov puni potencijal, zemlje u regionu mogle bi dobiti po glavi stanovnika skoro onoliko nov\"\"\"\n",
        "print(extend_text(tekat, temperature=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRZYp5TtVk5_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}