{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06A036uUU2jA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "import re\n",
        "import sys\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9YRZhHTWiUR",
        "outputId": "35175d17-317e-4c13-8558-a89aa31f735a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tTh0aFnVXzx"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHcVu_BGhnT5"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3sv8fpaVGQq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Seferovic/bosnian-news-articles-dataset-from-klixba\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37av5t32VXQb"
      },
      "outputs": [],
      "source": [
        "df = ds['train'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "X5aSyeb0Xbct",
        "outputId": "759bfd9b-68e3-4c26-ef9c-4b19ac6c2c9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>link</th>\n",
              "      <th>article_class</th>\n",
              "      <th>article_class_name</th>\n",
              "      <th>num_of_comments</th>\n",
              "      <th>num_of_shares</th>\n",
              "      <th>picture_path</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ukrajinski piloti započeli obuku za upravljanj...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/ukrajinski-...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Obučavaju ih Amerikanci</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Ukrajinski piloti započeli su zajedničku obuku...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Košarkaši BiH se danas protiv Poljske bore za ...</td>\n",
              "      <td>https://www.klix.ba/sport/kosarka/kosarkasi-bi...</td>\n",
              "      <td>sport</td>\n",
              "      <td>Finale pretkvalifikacija</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Košarkaška reprezentacija Bosne i Hercegovine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nakon više od 80 godina Kaliforniji se sprema ...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/nakon-vise-...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Uragan Hilary</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Uragan Hilary koji se kreće prema pacifičkoj o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kremlj je na popis stranih agenata u Rusiji uv...</td>\n",
              "      <td>https://www.klix.ba/vijesti/svijet/kremlj-je-n...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Paranoja u Moskvi</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/23...</td>\n",
              "      <td>Rusko ministarstvo pravde uključilo je na tako...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Savo Manojlović odgovorio Ani Brnabić: Da li s...</td>\n",
              "      <td>https://www.klix.ba/vijesti/regija/savo-manojl...</td>\n",
              "      <td>vijesti</td>\n",
              "      <td>Pitanje odgovornosti</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>https://static.klix.ba/media/images/vijesti/b_...</td>\n",
              "      <td>Direktor pokreta \"Kreni-Promeni\" Savo Manojlov...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Ukrajinski piloti započeli obuku za upravljanj...   \n",
              "1  Košarkaši BiH se danas protiv Poljske bore za ...   \n",
              "2  Nakon više od 80 godina Kaliforniji se sprema ...   \n",
              "3  Kremlj je na popis stranih agenata u Rusiji uv...   \n",
              "4  Savo Manojlović odgovorio Ani Brnabić: Da li s...   \n",
              "\n",
              "                                                link article_class  \\\n",
              "0  https://www.klix.ba/vijesti/svijet/ukrajinski-...       vijesti   \n",
              "1  https://www.klix.ba/sport/kosarka/kosarkasi-bi...         sport   \n",
              "2  https://www.klix.ba/vijesti/svijet/nakon-vise-...       vijesti   \n",
              "3  https://www.klix.ba/vijesti/svijet/kremlj-je-n...       vijesti   \n",
              "4  https://www.klix.ba/vijesti/regija/savo-manojl...       vijesti   \n",
              "\n",
              "         article_class_name  num_of_comments num_of_shares  \\\n",
              "0   Obučavaju ih Amerikanci                0             0   \n",
              "1  Finale pretkvalifikacija                8             0   \n",
              "2             Uragan Hilary               17            18   \n",
              "3         Paranoja u Moskvi                4            27   \n",
              "4      Pitanje odgovornosti                8             8   \n",
              "\n",
              "                                        picture_path  \\\n",
              "0  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "1  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "2  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "3  https://static.klix.ba/media/images/vijesti/23...   \n",
              "4  https://static.klix.ba/media/images/vijesti/b_...   \n",
              "\n",
              "                                                text  \n",
              "0  Ukrajinski piloti započeli su zajedničku obuku...  \n",
              "1  Košarkaška reprezentacija Bosne i Hercegovine ...  \n",
              "2  Uragan Hilary koji se kreće prema pacifičkoj o...  \n",
              "3  Rusko ministarstvo pravde uključilo je na tako...  \n",
              "4  Direktor pokreta \"Kreni-Promeni\" Savo Manojlov...  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xPfaLMUXk1p"
      },
      "outputs": [],
      "source": [
        "text = df['text'].values[:1500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3oHEZGyaQrH"
      },
      "outputs": [],
      "source": [
        "text = ''.join(text)\n",
        "text = text[:1_050_000].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIRXyiXXa2NC",
        "outputId": "0fa9b801-101f-46c7-ed00-3a860ddeef8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1050003"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTUGgwlqelto"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mtWZs0FMqnh",
        "outputId": "9bbabff6-9ecf-42b8-da0e-3b3737e5db68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'š', 'đ', 'ž', 'č', 'ć', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '?', '.', ',', '\"', '(', ')', '+', '-', '/', '@', '%', '–', \"'\", ':', ' ', '\\n']\n"
          ]
        }
      ],
      "source": [
        "accepted_text= string.ascii_lowercase + 'šđžčć' + string.digits + '!?.,\"()+-/@%–' + \"':\" + ' ' + '\\n'\n",
        "chars = [x for x in accepted_text]\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftNIYLSGYztB"
      },
      "outputs": [],
      "source": [
        "text = ''.join([char for char in text if char in accepted_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozofNyJbd-IH"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20\n",
        "train_text = text[:int(len(text)*(1-test_size))]\n",
        "test_text = text[int(len(text)*(1-test_size)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR-UN4k3fac7",
        "outputId": "deb4186b-e1f4-4370-c66a-3c5534285df7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(838059, 209515)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_text), len(test_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-AcUe3Uhr6G"
      },
      "source": [
        "## Create vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEyp7_THVhi6"
      },
      "outputs": [],
      "source": [
        "vocab={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE9IdEKwOTGP"
      },
      "outputs": [],
      "source": [
        "for i, char in enumerate(chars):\n",
        "  vocab[char] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R89xd0_4PAIw",
        "outputId": "3aa4c601-35da-4eeb-ed82-95854e3b4e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 58\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTElt8NhcXm"
      },
      "source": [
        "## Create Custom tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OMntxT_gvR5"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "  def __init__(self,vocabulary):\n",
        "    self.vocabulary=vocabulary\n",
        "\n",
        "  def __call__(self,sequence, label=False):\n",
        "    sequence = sequence.lower()\n",
        "    if label:\n",
        "      token = F.one_hot(torch.tensor(self.vocabulary[sequence]),num_classes=len(self.vocabulary))\n",
        "      return token.type(torch.float32)\n",
        "    tokens =[]\n",
        "    for letter in sequence:\n",
        "      tokens.append(self.vocabulary[letter])\n",
        "    return torch.tensor(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95KSR07NXt7t"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AmykNE2gLoR"
      },
      "source": [
        "## Create Custom dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBSUpM46Z8CH"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self,text,T,tokenizer=None):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.text = text\n",
        "    self.T = T\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)-self.T\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    x = self.text[idx:idx+self.T]\n",
        "    y = self.text[idx+self.T]\n",
        "\n",
        "    if self.tokenizer:\n",
        "      x = self.tokenizer(x)\n",
        "      y = self.tokenizer(y, label=True)\n",
        "\n",
        "\n",
        "    #x = x.astype(np.float32)\n",
        "   # y = np.array(y).reshape(-1,1).astype(np.float32)\n",
        "    return x.long(), y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yppR6NQygH5T"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AFpYZcmcpl7"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_text,150,tokenizer=tokenizer)\n",
        "test_dataset = TextDataset(test_text,150,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLC0REiedURt",
        "outputId": "a4c78fd9-9a4f-4897-cac7-224fc6f1f49c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(837909, 209365)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9BPv29Yc6iV",
        "outputId": "9235b866-ecb1-4a9a-fa3a-7e15e2abbf10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([20, 10, 17,  0,  9,  8, 13, 18, 10,  8, 56, 15,  8, 11, 14, 19,  8, 56,\n",
            "        25,  0, 15, 14, 29,  4, 11,  8, 56, 18, 20, 56, 25,  0,  9,  4,  3, 13,\n",
            "         8, 29, 10, 20, 56, 14,  1, 20, 10, 20, 56, 25,  0, 56, 20, 15, 17,  0,\n",
            "        21, 11,  9,  0, 13,  9,  4, 56,  1, 14, 17,  1,  4, 13,  8, 12, 56,  0,\n",
            "        21,  8, 14, 13,  8, 12,  0, 56,  5, 49, 32, 37, 56, 18,  0, 56,  0, 12,\n",
            "         4, 17,  8, 29, 10,  8, 12, 56,  8, 13, 18, 19, 17, 20, 10, 19, 14, 17,\n",
            "         8, 12,  0, 56, 20, 56, 20, 10, 17,  0,  9,  8, 13,  8, 43, 56, 14, 21,\n",
            "        20, 56,  8, 13,  5, 14, 17, 12,  0,  2,  8,  9, 20, 56,  9,  4, 56, 25,\n",
            "         0, 56, 12,  4,  3,  8]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "for i,k in train_dataset:\n",
        "  print(i,k)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8WD7ZI0iBgk"
      },
      "source": [
        "## Initilize DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCpde61bc_7W"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X5jy-PGMv5g",
        "outputId": "70020dff-aadf-491d-e6a0-a93b1c249f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:  tensor([[ 9,  4, 56,  ...,  4, 56,  8],\n",
            "        [ 0, 21, 13,  ..., 30,  4, 56],\n",
            "        [ 9,  0,  9,  ..., 21,  4, 30],\n",
            "        ...,\n",
            "        [18, 19,  0,  ...,  0, 21, 13],\n",
            "        [ 8, 56, 18,  ..., 18, 12,  0],\n",
            "        [56, 25,  0,  ..., 11,  8, 10]]) shape:  torch.Size([32, 150])\n",
            "targets:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) shape:  torch.Size([32, 58])\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_loader:\n",
        "  print('inputs: ', inputs, 'shape: ', inputs.shape)\n",
        "  print('targets: ', targets, 'shape: ', targets.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osP74uLsiDCI"
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxUNhBPKi4Nl",
        "outputId": "85698fc6-e72e-4dac-db5a-0692e7e94a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naMGrVxjiE7a"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,n_hidden,n_layers,n_outputs):\n",
        "    super(RNN,self).__init__()\n",
        "    self.V = vocab_size\n",
        "    self.D = embed_size\n",
        "    self.M = n_hidden\n",
        "    self.L = n_layers\n",
        "    self.K = n_outputs\n",
        "\n",
        "    self.embedding = nn.Embedding(self.V,self.D)\n",
        "\n",
        "    # Initalize rnn and fc layers\n",
        "    self.rnn = nn.LSTM(input_size=self.D,\n",
        "                      hidden_size=self.M,\n",
        "                      num_layers=self.L,\n",
        "                      dropout=0.5,\n",
        "                      batch_first=True)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.M, self.K),\n",
        "         # nn.ReLU(),\n",
        "         # nn.Linear(1024, 512),\n",
        "         # nn.ReLU(),\n",
        "         # nn.Linear(512,self.K)\n",
        "        )\n",
        "\n",
        "  def forward(self, X, hidden):\n",
        "    # Embedding layer:\n",
        "\n",
        "    out = self.embedding(X)\n",
        "    # pass through rnn\n",
        "\n",
        "    out,hidden_state= self.rnn(out,hidden)\n",
        "   # out = F.relu(out)\n",
        "    out = self.fc(out[:,-1,:])\n",
        "    return out,(hidden_state[0].detach(), hidden_state[1].detach())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTbeyEnfjD7v",
        "outputId": "38a27bf5-c9fe-400a-f482-af3433fec322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(58, 4)\n",
              "  (rnn): LSTM(4, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=58, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RNN(vocab_size=vocab_size,\n",
        "            embed_size=4,\n",
        "            n_hidden=512,\n",
        "            n_layers=3,\n",
        "            n_outputs=vocab_size)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQDwNhIhKZdT",
        "outputId": "6e2a73f5-d203-4c35-c5cc-4e860551d697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlGZoZ8FjVkw",
        "outputId": "8fda6a7d-67a3-4db0-f644-61e658004831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 150])\n",
            "torch.Size([32, 58])\n"
          ]
        }
      ],
      "source": [
        "for i, k in train_loader:\n",
        "  print(i.shape)\n",
        "  tada,_ = model(i.to(device), None)\n",
        "  print(tada.size())\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Web7uUkljiAX"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XPgERT9mkFX"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbAbUut_mysE"
      },
      "outputs": [],
      "source": [
        "from helper_functions import progress_bar, plot_loss_curves,SaveModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpteePwWwyro"
      },
      "outputs": [],
      "source": [
        "save_model_checkpoint = SaveModelCheckpoint(path=\"model3_checkpoint.pt\")\n",
        "best_val_loss=float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "qVT2RHKam6D7",
        "outputId": "85d749cd-38f7-4d46-bd36-f04a17911b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 1, val_loss improved from: inf to: 2.2146\u001b[0m\n",
            "Epoch 1/30, Train loss: 2.5928, Val loss: 2.2146, Duration: 0:13:06.850978\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 2, val_loss improved from: 2.2146 to: 1.7368\u001b[0m\n",
            "Epoch 2/30, Train loss: 1.9021, Val loss: 1.7368, Duration: 0:13:04.222969\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 3, val_loss improved from: 1.7368 to: 1.6533\u001b[0m\n",
            "Epoch 3/30, Train loss: 1.7168, Val loss: 1.6533, Duration: 0:13:02.575257\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 4, val_loss improved from: 1.6533 to: 1.6023\u001b[0m\n",
            "Epoch 4/30, Train loss: 1.6343, Val loss: 1.6023, Duration: 0:13:03.856296\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 5, val_loss improved from: 1.6023 to: 1.5785\u001b[0m\n",
            "Epoch 5/30, Train loss: 1.5818, Val loss: 1.5785, Duration: 0:13:03.688156\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 6, val_loss improved from: 1.5785 to: 1.5580\u001b[0m\n",
            "Epoch 6/30, Train loss: 1.5463, Val loss: 1.5580, Duration: 0:13:04.397640\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 7, val_loss improved from: 1.5580 to: 1.5438\u001b[0m\n",
            "Epoch 7/30, Train loss: 1.5182, Val loss: 1.5438, Duration: 0:13:03.144979\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 8, val_loss improved from: 1.5438 to: 1.5369\u001b[0m\n",
            "Epoch 8/30, Train loss: 1.4953, Val loss: 1.5369, Duration: 0:13:02.014756\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 9, val_loss improved from: 1.5369 to: 1.5299\u001b[0m\n",
            "Epoch 9/30, Train loss: 1.4768, Val loss: 1.5299, Duration: 0:13:02.691647\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 10, val_loss improved from: 1.5299 to: 1.5257\u001b[0m\n",
            "Epoch 10/30, Train loss: 1.4629, Val loss: 1.5257, Duration: 0:13:02.902972\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 11, val_loss improved from: 1.5257 to: 1.5216\u001b[0m\n",
            "Epoch 11/30, Train loss: 1.4485, Val loss: 1.5216, Duration: 0:13:03.458803\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 12, val_loss improved from: 1.5216 to: 1.5181\u001b[0m\n",
            "Epoch 12/30, Train loss: 1.4360, Val loss: 1.5181, Duration: 0:12:46.643527\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 13, val_loss improved from: 1.5181 to: 1.5158\u001b[0m\n",
            "Epoch 13/30, Train loss: 1.4248, Val loss: 1.5158, Duration: 0:12:46.361378\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 14/30, Train loss: 1.4149, Val loss: 1.5164, Duration: 0:12:47.083346\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 15, val_loss improved from: 1.5158 to: 1.5142\u001b[0m\n",
            "Epoch 15/30, Train loss: 1.4056, Val loss: 1.5142, Duration: 0:12:46.192979\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "\u001b[92m\u001b[1mModel saved at epoch: 16, val_loss improved from: 1.5142 to: 1.5091\u001b[0m\n",
            "Epoch 16/30, Train loss: 1.3946, Val loss: 1.5091, Duration: 0:12:47.136332\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 17/30, Train loss: 1.3865, Val loss: 1.5179, Duration: 0:12:46.394374\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 18/30, Train loss: 1.3787, Val loss: 1.5162, Duration: 0:12:46.649829\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 19/30, Train loss: 1.3713, Val loss: 1.5106, Duration: 0:12:45.558030\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 20/30, Train loss: 1.3636, Val loss: 1.5134, Duration: 0:12:47.227163\n",
            "-------------------------------------------------------------\n",
            "Validation: Batch 6542/6542 - [==================================================]\n",
            "Epoch 21/30, Train loss: 1.3560, Val loss: 1.5104, Duration: 0:12:47.136826\n",
            "-------------------------------------------------------------\n",
            "Batch 6230/26184 - [===========.......................................]"
          ]
        }
      ],
      "source": [
        "epoches=30\n",
        "train_losses = np.zeros(epoches)\n",
        "val_losses = np.zeros(epoches)\n",
        "for it in range(epoches):\n",
        "  t0 = datetime.now()\n",
        "  current_batch = 0\n",
        "  total_batches = len(train_loader)\n",
        "  model.train() # set model to train mode\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  hidden_state = None\n",
        "  # train\n",
        "  for inputs,targets in train_loader:\n",
        "    # move data to gpu\n",
        "    inputs,targets = inputs.to(device),targets.to(device)\n",
        "    #inputs = inputs.permute(0,2,1)\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    outputs,hidden_state = model(inputs,hidden_state)\n",
        "    loss = criterion(outputs,targets)\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.item())\n",
        "    current_batch = progress_bar(current_batch,total_batches)\n",
        "\n",
        "  model.eval() # set model to eval mode\n",
        "  current_batch = 0\n",
        "  total_batches = len(test_loader)\n",
        "  for inputs,targets in test_loader:\n",
        "    # move data to gpu\n",
        "    inputs,targets = inputs.to(device),targets.to(device)\n",
        "   # inputs = inputs.permute(0,2,1)\n",
        "\n",
        "\n",
        "    # forward pass\n",
        "    outputs,hidden_state = model(inputs,hidden_state)\n",
        "    loss = criterion(outputs,targets)\n",
        "\n",
        "    val_loss.append(loss.item())\n",
        "    current_batch = progress_bar(current_batch,total_batches,validation=True)\n",
        "\n",
        "\n",
        "  # calculate loss\n",
        "  print('\\r')\n",
        "  train_loss = np.mean(train_loss)\n",
        "  val_loss = np.mean(val_loss)\n",
        "  best_val_loss=  save_model_checkpoint(val_loss,best_val_loss,train_loss,it, model=model, optimizer=optimizer)\n",
        "\n",
        "  # append loss\n",
        "  train_losses[it]=train_loss\n",
        "  val_losses[it]=val_loss\n",
        "  dt = datetime.now() - t0\n",
        "  print(f\"Epoch {it+1}/{epoches}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Duration: {dt}\")\n",
        "  print('-------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaBW9j7em_lx"
      },
      "outputs": [],
      "source": [
        "print_second = False\n",
        "if print_second:\n",
        "  plot_loss_curves(train_losses2,val_losses2,train_losses,val_losses,)\n",
        "else:\n",
        "  plot_loss_curves(train_losses,val_losses)\n",
        "  train_losses2,val_losses2 = train_losses,val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZdfDtlYwufB"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "# train accuracy\n",
        "n_correct=0\n",
        "n_total=0\n",
        "for inputs,targets in train_loader:\n",
        "  # move data to gpu\n",
        "  inputs,targets = inputs.to(device),targets.to(device)\n",
        "  #inputs = inputs.permute(0,2,1)\n",
        "\n",
        "  # make prediction\n",
        "  outputs = model(inputs)\n",
        "  _,predictions = torch.max(outputs,1)\n",
        "  targets = torch.argmax(targets, dim=1)\n",
        "  # update counts\n",
        "  n_correct+=(predictions==targets).sum().item()\n",
        "  n_total+=targets.shape[0]\n",
        "train_acc = n_correct/n_total\n",
        "\n",
        "# test accuracy\n",
        "n_correct=0\n",
        "n_total=0\n",
        "for inputs,targets in test_loader:\n",
        "  # move data to gpu\n",
        "  inputs,targets = inputs.to(device),targets.to(device)\n",
        "  #inputs = inputs.permute(0,2,1)\n",
        "\n",
        "  # make prediction\n",
        "  outputs = model(inputs)\n",
        "  _,predictions = torch.max(outputs,1)\n",
        "  targets = torch.argmax(targets, dim=1)\n",
        "  # update counts\n",
        "  n_correct+=(predictions==targets).sum().item()\n",
        "  n_total+=targets.shape[0]\n",
        "test_acc = n_correct/n_total\n",
        "\n",
        "print(f\"Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ESAAD6fGl7"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    model = RNN(vocab_size=vocab_size,\n",
        "                embed_size=4,\n",
        "                n_hidden=512,\n",
        "                n_layers=3,\n",
        "                n_outputs=vocab_size)\n",
        "    model.to(device)\n",
        "    model.to(device)\n",
        "    model.load_state_dict(torch.load('model3_checkpoint.pt',map_location=device)['model_state_dict'])\n",
        "    model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDq95uETDYti"
      },
      "outputs": [],
      "source": [
        "vocabulary = {y: x for x, y in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUAAH3gqEOju"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y5ZT9mN9945",
        "outputId": "7acf19f7-3ce6-4f4f-a628-880021fa99bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FK Željezničar je uoči sjednice obavijestio medije dai\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n",
            "FK Željezničar je uoči sjednice obavijestio medije daiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
            "---------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tekst = text[500000:500100]\n",
        "hidden_state=None\n",
        "tekst='FK Željezničar je uoči sjednice obavijestio medije da'\n",
        "#tekst = '''Apsolutni junak Zmajeva večeras je bio golman Nikola Vasilj, koji je sa pet izvanrednih intervencija sačuvao svoju mrežu netaknutom, pa je najzaslužniji za osvojeni bod našeg nacionalnog tima.#\n",
        "#Od početka utakmice inicijativu je imala selekcija Mađarske, ali ipak se dugo čekalo na prava uzbuđenja jer smo gledali uspavanku na terenu.'''\n",
        "for i in range(50):\n",
        "  data = tokenizer(tekst[-100:])\n",
        "  data = data.reshape(1,-1)\n",
        "  data = data.to(device)\n",
        "  outputs,hidden_state = model(inputs,hidden_state)\n",
        "  out = torch.argmax(outputs,1)\n",
        "  new_letter = vocabulary[out.cpu().numpy()[0]]\n",
        "  tekst = tekst+new_letter\n",
        "  print(tekst)\n",
        "  time.sleep(0.5)\n",
        "  print('---------------------------------------------------')\n",
        "#print(tekst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47wRFrhPAhy_"
      },
      "outputs": [],
      "source": [
        "def next_char(text, hidden_state,temperature=1):\n",
        "    # Predict using the model (assuming text is already processed into the right tensor format)\n",
        "    with torch.no_grad():\n",
        "      data = tokenizer(text)\n",
        "      data = data.reshape(1,-1)\n",
        "      data = data.to(device)\n",
        "      logits,hidden_state = model(data,hidden_state)  # Replace with proper text input processing\n",
        "\n",
        "    # Get the logits for the last predicted character\n",
        "    #logits = y_proba[:, -1, :]  # Assuming y_proba has shape [batch_size, seq_len, vocab_size]\n",
        "\n",
        "    # Rescale logits using temperature\n",
        "    rescaled_logits = logits / temperature\n",
        "\n",
        "    # Apply softmax to get probabilities and then sample from the categorical distribution\n",
        "    probabilities = F.softmax(rescaled_logits, dim=-1)\n",
        "    char_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "\n",
        "    # Get the vocabulary and return the corresponding character\n",
        "    return vocabulary[char_id], hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN0xodgUVbVr"
      },
      "outputs": [],
      "source": [
        "def extend_text(text, n_chars=200, temperature=1):\n",
        "    hidden_state=None\n",
        "    class bcolors:\n",
        "        HEADER = '\\033[95m'\n",
        "        OKBLUE = '\\033[94m'\n",
        "        OKCYAN = '\\033[96m'\n",
        "        OKGREEN = '\\033[92m'\n",
        "        WARNING = '\\033[93m'\n",
        "        FAIL = '\\033[91m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        UNDERLINE = '\\033[4m'\n",
        "\n",
        "    first_len=len(text)\n",
        "    for _ in range(n_chars):\n",
        "        char,hidden_state = next_char(text, hidden_state,temperature)\n",
        "        text+=char\n",
        "    print(f\"{bcolors.OKGREEN}{text[:first_len]}{bcolors.ENDC}{text[first_len:]}\")\n",
        "\n",
        "    #return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVN4d2G5fGl8"
      },
      "outputs": [],
      "source": [
        "telst = \"Osim toga, u biltenu MUP-a KS se navodi da su u toku proteklog dana, službenici policije, preduzimajući redovne mjere kontrole saobraćaja, uručili su 554 prekršajna naloga, iz saobraćaja je isključeno 19 vozača zbog up\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G5tLomVVcLs",
        "outputId": "cd4368ea-3055-4d23-be6b-91ec16537a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mOsim toga, u biltenu MUP-a KS se navodi da su u toku proteklog dana, službenici policije, preduzimajući redovne mjere kontrole saobraćaja, uručili su 554 prekršajna naloga, iz saobraćaja je isključeno 19 vozača zbog up\u001b[0mrava i kako nije projektila na procesu prethodnog procesa koji je na parkinu i predsjednik moralo da se protiv ministarstva unutrašnjih poslova koji su odbrani sa ukrajinima grada kao drugim glavnom p\n"
          ]
        }
      ],
      "source": [
        "extend_text(telst, temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_emxBUBzfGl8",
        "outputId": "181ac7c3-a314-4f00-cff9-a1aaca79453e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mOsim toga, u biltenu MUP-a KS se navodi da su u toku proteklog dana, službenici policije, preduzimajući redovne mjere kontrole saobraćaja, uručili su 554 prekršajna naloga, iz saobraćaja je isključeno 19 vozača zbog up\u001b[0mravljanja protiv miliona u sarajevu i izbjeglice su predstavlja predstavnika postavlja se na startu kao i posljednjih poslova u posljednji se da se na takmičenju i protiv predsjednika bit će se od 100\n"
          ]
        }
      ],
      "source": [
        "extend_text(telst, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORwbqV7cVg0F",
        "outputId": "74ff7dd8-74d7-497b-d0c6-4025493cc48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mOsim toga, u biltenu MUP-a KS se navodi da su u toku proteklog dana, službenici policije, preduzimajući redovne mjere kontrole saobraćaja, uručili su 554 prekršajna naloga, iz saobraćaja je isključeno 19 vozača zbog up\u001b[0mravljanja protiv predsjednika protiv selekcije bih u sarajevu i predsjednika bilo je potvrdio da su se do posljednjih poslova u sarajevu i predsjednika bilo je potvrdio da su se do posljednjih poslova\n"
          ]
        }
      ],
      "source": [
        "extend_text(telst, temperature=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRZYp5TtVk5_",
        "scrolled": true,
        "outputId": "8efd0aa2-fe24-4be3-b9dd-67f9dd84c820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mOsim toga, u biltenu MUP-a KS se navodi da su u toku proteklog dana, službenici policije, preduzimajući redovne mjere kontrole saobraćaja, uručili su 554 prekršajna naloga, iz saobraćaja je isključeno 19 vozača zbog up\u001b[0mravljanja protiv predsjednika protiv selekcije bih u sarajevu i predsjednika bilo je potvrdio da su se do posljednjih poslova u sarajevu i predsjednika bilo je potvrdio da su se do posljednjih poslova\n"
          ]
        }
      ],
      "source": [
        "extend_text(telst, temperature=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b0de28-0718-4ee4-8b84-fc0176781fcb",
        "id": "iVK7KTX-fGl8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mAli, želja Ukrajine za članstvom u EU posebno je stvorila opipljiv strah na zapadnom Balkanu da će biti ostavljena po strani. Srbija ne želi da ima ništa sa NATO-om, a njen blizak odnos sa Moskvom zakomplikovao je nastojanja Beograda za ulazak u EU, još više od ruske invazije velikih razmjera na Ukrajinu.\n",
            "\n",
            "Da nije bilo invazije na Ukrajinu, pristupni pregovori sa Albanijom i Sjevernom Makedonijom zasigurno bi zaglavili, a Bosna i Hercegovina ne bi bila priznata kao kandidat za EU. Možda se i EU ne bi složila oko budžeta za svoj novi plan rasta od šest milijardi eura za Zapadni Balkan. Plan uslovljava evropska ulaganja reformama na Balkanu, ali ako se ostvari njegov puni potencijal, zemlje u regionu mogle bi dobiti po glavi stanovnika skoro onoliko nov\u001b[0minarske lige je ministarstva na svoje druge šta je na sjevernoj putu predmeta u procesu svoje potpuno da je samo da se različita pod svemirskom kompanijom za od posljednjeg zakona i to su planira da s\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "tekat=\"\"\"Ali, želja Ukrajine za članstvom u EU posebno je stvorila opipljiv strah na zapadnom Balkanu da će biti ostavljena po strani. Srbija ne želi da ima ništa sa NATO-om, a njen blizak odnos sa Moskvom zakomplikovao je nastojanja Beograda za ulazak u EU, još više od ruske invazije velikih razmjera na Ukrajinu.\n",
        "\n",
        "Da nije bilo invazije na Ukrajinu, pristupni pregovori sa Albanijom i Sjevernom Makedonijom zasigurno bi zaglavili, a Bosna i Hercegovina ne bi bila priznata kao kandidat za EU. Možda se i EU ne bi složila oko budžeta za svoj novi plan rasta od šest milijardi eura za Zapadni Balkan. Plan uslovljava evropska ulaganja reformama na Balkanu, ali ako se ostvari njegov puni potencijal, zemlje u regionu mogle bi dobiti po glavi stanovnika skoro onoliko nov\"\"\"\n",
        "print(extend_text(tekat, temperature=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWxwxVGZfGl8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}